# This workflow will build and push a new container image to Amazon ECR,
# and then will deploy a new task definition to Amazon ECS, when there is a push to the "main" branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ECR repository to store your images.
#    For example: `aws ecr create-repository --repository-name my-ecr-repo --region us-east-2`.
#    Replace the value of the `ECR_REPOSITORY` environment variable in the workflow below with your repository's name.
#    Replace the value of the `AWS_REGION` environment variable in the workflow below with your repository's region.
#
# 2. Create an ECS task definition, an ECS cluster, and an ECS service.
#    For example, follow the Getting Started guide on the ECS console:
#      https://us-east-2.console.aws.amazon.com/ecs/home?region=us-east-2#/firstRun
#    Replace the value of the `ECS_SERVICE` environment variable in the workflow below with the name you set for the Amazon ECS service.
#    Replace the value of the `ECS_CLUSTER` environment variable in the workflow below with the name you set for the cluster.
#
# 3. Store your ECS task definition as a JSON file in your repository.
#    The format should follow the output of `aws ecs register-task-definition --generate-cli-skeleton`.
#    Replace the value of the `ECS_TASK_DEFINITION` environment variable in the workflow below with the path to the JSON file.
#    Replace the value of the `CONTAINER_NAME` environment variable in the workflow below with the name of the container
#    in the `containerDefinitions` section of the task definition.
#
# 4. Store an IAM user access key in GitHub Actions secrets named `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.
#    See the documentation for each action used below for the recommended IAM policies for this IAM user,
#    and best practices on handling the access key credentials.

name: Deploy Flask to Amazon ECS2 Machine

on: workflow_dispatch

# on:
#   push:
#     branches: [ "main" ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          path: dynamo-python-etl
      - name: Use SSH Copy to Clone Repo
        uses: appleboy/scp-action@master
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{secrets.PRIVATE_KEY}}
          port: ${{ secrets.PORT }}
          source: "dynamo-python-etl"
          target: "/home/ubuntu"
      - name: multiple command
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{secrets.HOST}}
          port: ${{secrets.PORT}}
          username: ${{secrets.USERNAME}}
          key: ${{secrets.PRIVATE_KEY}}
          script_stop: true
          script: |
            whoami
            cd dynamo-python-etl
            ls -al
            sudo apt-get update -y
            sudo apt-get install -y python3-venv
            sudo python3 -m venv flaskenv
            source flaskenv/bin/activate
            sudo chmod -R a+rwx flaskenv/
            pip install -r requirements.txt
            sudo cp -f /home/ubuntu/dynamo-python-etl/ssh_files/flask_app.service /etc/systemd/system/flask_app.service
            sudo systemctl daemon-reload
            sudo systemctl start flask_app
            sudo systemctl enable flask_app
            sudo apt-get install -y nginx
            sudo cp -f /home/ubuntu/dynamo-python-etl/ssh_files/default /etc/nginx/sites-available/default
            # Check if Nginx is running
            if sudo systemctl is-active nginx >/dev/null 2>&1; then
                sudo systemctl restart nginx   # Restart Nginx if it's already running
            else
                sudo systemctl enable nginx   # Enable Nginx to start on boot
                sudo systemctl start nginx   # Start Nginx if it's not running
            fi
